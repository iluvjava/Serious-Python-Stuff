"""
    First order optimizer.
    Use finite diff to approximate Hessian.
    Use both newton's or accelerated gradient, which ever is better.
    When gradient is small, it start to random sample using local hessian and the sequence of descned parameters.
"""

class MyHybridOptimizer:
    def __int__(this):
        pass


def main():
    pass


if __name__ == "__main__":
    import os
    print(f"{os.curdir}")
    print(f"{os.getcwd()}")
    main()





